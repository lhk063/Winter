{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
<<<<<<< HEAD:데이콘/컴퓨터 비전 학습 경진대회/85percent.ipynb
   "name": "python_defaultSpec_1600123160508",
=======
   "name": "python_defaultSpec_1599971297487",
>>>>>>> parent of 9612ab3... 14-Sep-2020:데이콘/컴퓨터 비전 학습 경진대회/새 폴더/85percent.ipynb
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 다중 입력 모델 (깊이별 분리 합성곱)\n",
    "- ### CNN + LSTM\n",
    "- ### OPTIMIZER : RAdam(), loss : Categorical_Crossentropy, Metrics : Accuracy \n",
    "- ### Keras ImageDataGenerator 사용\n",
    "\n",
    "- #### Xception 구조와 LSTM 을 합쳐 보았다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
<<<<<<< HEAD:데이콘/컴퓨터 비전 학습 경진대회/85percent.ipynb
    "from keras.layers import Conv2D, SeparableConv2D, Dense, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, BatchNormalization, Dropout\n",
    "from keras.layers import Add\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import keras.backend as K\n",
    "%load_ext tensorboard\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'2.4.2'"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "keras.__version__"
=======
    "%load_ext tensorboard\n"
>>>>>>> parent of 9612ab3... 14-Sep-2020:데이콘/컴퓨터 비전 학습 경진대회/새 폴더/85percent.ipynb
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_radam import RAdam\n",
    "from tensorflow.python.keras.optimizer_v2.optimizer_v2 import OptimizerV2\n",
    "from tensorflow.python import ops, math_ops, state_ops, control_flow_ops\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "__all__ = ['RAdam']\n",
    "\n",
    "\n",
    "class RAdam(OptimizerV2):\n",
    "    \"\"\"RAdam optimizer.\n",
    "    According to the paper\n",
    "    [On The Variance Of The Adaptive Learning Rate And Beyond](https://arxiv.org/pdf/1908.03265v1.pdf).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 learning_rate=0.001,\n",
    "                 beta_1=0.9,\n",
    "                 beta_2=0.999,\n",
    "                 epsilon=1e-7,\n",
    "                 weight_decay=0.,\n",
    "                 amsgrad=False,\n",
    "                 total_steps=0,\n",
    "                 warmup_proportion=0.1,\n",
    "                 min_lr=0.,\n",
    "                 name='RAdam',\n",
    "                 **kwargs):\n",
    "        r\"\"\"Construct a new Adam optimizer.\n",
    "        Args:\n",
    "            learning_rate: A Tensor or a floating point value.    The learning rate.\n",
    "            beta_1: A float value or a constant float tensor. The exponential decay\n",
    "                rate for the 1st moment estimates.\n",
    "            beta_2: A float value or a constant float tensor. The exponential decay\n",
    "                rate for the 2nd moment estimates.\n",
    "            epsilon: A small constant for numerical stability. This epsilon is\n",
    "                \"epsilon hat\" in the Kingma and Ba paper (in the formula just before\n",
    "                Section 2.1), not the epsilon in Algorithm 1 of the paper.\n",
    "            weight_decay: A floating point value. Weight decay for each param.\n",
    "            amsgrad: boolean. Whether to apply AMSGrad variant of this algorithm from\n",
    "                the paper \"On the Convergence of Adam and beyond\".\n",
    "            total_steps: An integer. Total number of training steps.\n",
    "                Enable warmup by setting a positive value.\n",
    "            warmup_proportion: A floating point value. The proportion of increasing steps.\n",
    "            min_lr: A floating point value. Minimum learning rate after warmup.\n",
    "            name: Optional name for the operations created when applying gradients.\n",
    "                Defaults to \"Adam\".    @compatibility(eager) When eager execution is\n",
    "                enabled, `learning_rate`, `beta_1`, `beta_2`, and `epsilon` can each be\n",
    "                a callable that takes no arguments and returns the actual value to use.\n",
    "                This can be useful for changing these values across different\n",
    "                invocations of optimizer functions. @end_compatibility\n",
    "            **kwargs: keyword arguments. Allowed to be {`clipnorm`, `clipvalue`, `lr`,\n",
    "                `decay`}. `clipnorm` is clip gradients by norm; `clipvalue` is clip\n",
    "                gradients by value, `decay` is included for backward compatibility to\n",
    "                allow time inverse decay of learning rate. `lr` is included for backward\n",
    "                compatibility, recommended to use `learning_rate` instead.\n",
    "        \"\"\"\n",
    "\n",
    "        super(RAdam, self).__init__(name, **kwargs)\n",
    "        self._set_hyper('learning_rate', kwargs.get('lr', learning_rate))\n",
    "        self._set_hyper('beta_1', beta_1)\n",
    "        self._set_hyper('beta_2', beta_2)\n",
    "        self._set_hyper('decay', self._initial_decay)\n",
    "        self._set_hyper('weight_decay', weight_decay)\n",
    "        self._set_hyper('total_steps', float(total_steps))\n",
    "        self._set_hyper('warmup_proportion', warmup_proportion)\n",
    "        self._set_hyper('min_lr', min_lr)\n",
    "        self.epsilon = epsilon or K.epsilon()\n",
    "        self.amsgrad = amsgrad\n",
    "        self._initial_weight_decay = weight_decay\n",
    "        self._initial_total_steps = total_steps\n",
    "\n",
    "    def _create_slots(self, var_list):\n",
    "        for var in var_list:\n",
    "            self.add_slot(var, 'm')\n",
    "        for var in var_list:\n",
    "            self.add_slot(var, 'v')\n",
    "        if self.amsgrad:\n",
    "            for var in var_list:\n",
    "                self.add_slot(var, 'vhat')\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        params = self.weights\n",
    "        num_vars = int((len(params) - 1) / 2)\n",
    "        if len(weights) == 3 * num_vars + 1:\n",
    "            weights = weights[:len(params)]\n",
    "        super(RAdam, self).set_weights(weights)\n",
    "\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        lr_t = self._decayed_lr(var_dtype)\n",
    "        m = self.get_slot(var, 'm')\n",
    "        v = self.get_slot(var, 'v')\n",
    "        beta_1_t = self._get_hyper('beta_1', var_dtype)\n",
    "        beta_2_t = self._get_hyper('beta_2', var_dtype)\n",
    "        epsilon_t = ops.convert_to_tensor(self.epsilon, var_dtype)\n",
    "        local_step = math_ops.cast(self.iterations + 1, var_dtype)\n",
    "        beta_1_power = math_ops.pow(beta_1_t, local_step)\n",
    "        beta_2_power = math_ops.pow(beta_2_t, local_step)\n",
    "\n",
    "        if self._initial_total_steps > 0:\n",
    "            total_steps = self._get_hyper('total_steps', var_dtype)\n",
    "            warmup_steps = total_steps * self._get_hyper('warmup_proportion', var_dtype)\n",
    "            min_lr = self._get_hyper('min_lr', var_dtype)\n",
    "            decay_steps = K.maximum(total_steps - warmup_steps, 1)\n",
    "            decay_rate = (min_lr - lr_t) / decay_steps\n",
    "            lr_t = tf.where(\n",
    "                local_step <= warmup_steps,\n",
    "                lr_t * (local_step / warmup_steps),\n",
    "                lr_t + decay_rate * K.minimum(local_step - warmup_steps, decay_steps),\n",
    "            )\n",
    "\n",
    "        sma_inf = 2.0 / (1.0 - beta_2_t) - 1.0\n",
    "        sma_t = sma_inf - 2.0 * local_step * beta_2_power / (1.0 - beta_2_power)\n",
    "\n",
    "        m_t = state_ops.assign(m,\n",
    "                               beta_1_t * m + (1.0 - beta_1_t) * grad,\n",
    "                               use_locking=self._use_locking)\n",
    "        m_corr_t = m_t / (1.0 - beta_1_power)\n",
    "\n",
    "        v_t = state_ops.assign(v,\n",
    "                               beta_2_t * v + (1.0 - beta_2_t) * math_ops.square(grad),\n",
    "                               use_locking=self._use_locking)\n",
    "        if self.amsgrad:\n",
    "            vhat = self.get_slot(var, 'vhat')\n",
    "            vhat_t = state_ops.assign(vhat,\n",
    "                                      math_ops.maximum(vhat, v_t),\n",
    "                                      use_locking=self._use_locking)\n",
    "            v_corr_t = math_ops.sqrt(vhat_t / (1.0 - beta_2_power))\n",
    "        else:\n",
    "            vhat_t = None\n",
    "            v_corr_t = math_ops.sqrt(v_t / (1.0 - beta_2_power))\n",
    "\n",
    "        r_t = math_ops.sqrt((sma_t - 4.0) / (sma_inf - 4.0) *\n",
    "                            (sma_t - 2.0) / (sma_inf - 2.0) *\n",
    "                            sma_inf / sma_t)\n",
    "\n",
    "        var_t = tf.where(sma_t >= 5.0, r_t * m_corr_t / (v_corr_t + epsilon_t), m_corr_t)\n",
    "\n",
    "        if self._initial_weight_decay > 0.0:\n",
    "            var_t += self._get_hyper('weight_decay', var_dtype) * var\n",
    "\n",
    "        var_update = state_ops.assign_sub(var,\n",
    "                                          lr_t * var_t,\n",
    "                                          use_locking=self._use_locking)\n",
    "\n",
    "        updates = [var_update, m_t, v_t]\n",
    "        if self.amsgrad:\n",
    "            updates.append(vhat_t)\n",
    "        return control_flow_ops.group(*updates)\n",
    "\n",
    "    def _resource_apply_sparse(self, grad, var, indices):\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        lr_t = self._decayed_lr(var_dtype)\n",
    "        beta_1_t = self._get_hyper('beta_1', var_dtype)\n",
    "        beta_2_t = self._get_hyper('beta_2', var_dtype)\n",
    "        epsilon_t = ops.convert_to_tensor(self.epsilon, var_dtype)\n",
    "        local_step = math_ops.cast(self.iterations + 1, var_dtype)\n",
    "        beta_1_power = math_ops.pow(beta_1_t, local_step)\n",
    "        beta_2_power = math_ops.pow(beta_2_t, local_step)\n",
    "\n",
    "        if self._initial_total_steps > 0:\n",
    "            total_steps = self._get_hyper('total_steps', var_dtype)\n",
    "            warmup_steps = total_steps * self._get_hyper('warmup_proportion', var_dtype)\n",
    "            min_lr = self._get_hyper('min_lr', var_dtype)\n",
    "            decay_steps = K.maximum(total_steps - warmup_steps, 1)\n",
    "            decay_rate = (min_lr - lr_t) / decay_steps\n",
    "            lr_t = tf.where(\n",
    "                local_step <= warmup_steps,\n",
    "                lr_t * (local_step / warmup_steps),\n",
    "                lr_t + decay_rate * K.minimum(local_step - warmup_steps, decay_steps),\n",
    "            )\n",
    "\n",
    "        sma_inf = 2.0 / (1.0 - beta_2_t) - 1.0\n",
    "        sma_t = sma_inf - 2.0 * local_step * beta_2_power / (1.0 - beta_2_power)\n",
    "\n",
    "        m = self.get_slot(var, 'm')\n",
    "        m_scaled_g_values = grad * (1 - beta_1_t)\n",
    "        m_t = state_ops.assign(m, m * beta_1_t, use_locking=self._use_locking)\n",
    "        with ops.control_dependencies([m_t]):\n",
    "            m_t = self._resource_scatter_add(m, indices, m_scaled_g_values)\n",
    "        m_corr_t = m_t / (1.0 - beta_1_power)\n",
    "\n",
    "        v = self.get_slot(var, 'v')\n",
    "        v_scaled_g_values = (grad * grad) * (1 - beta_2_t)\n",
    "        v_t = state_ops.assign(v, v * beta_2_t, use_locking=self._use_locking)\n",
    "        with ops.control_dependencies([v_t]):\n",
    "            v_t = self._resource_scatter_add(v, indices, v_scaled_g_values)\n",
    "\n",
    "        if self.amsgrad:\n",
    "            vhat = self.get_slot(var, 'vhat')\n",
    "            vhat_t = state_ops.assign(vhat,\n",
    "                                      math_ops.maximum(vhat, v_t),\n",
    "                                      use_locking=self._use_locking)\n",
    "            v_corr_t = math_ops.sqrt(vhat_t / (1.0 - beta_2_power))\n",
    "        else:\n",
    "            vhat_t = None\n",
    "            v_corr_t = math_ops.sqrt(v_t / (1.0 - beta_2_power))\n",
    "\n",
    "        r_t = math_ops.sqrt((sma_t - 4.0) / (sma_inf - 4.0) *\n",
    "                            (sma_t - 2.0) / (sma_inf - 2.0) *\n",
    "                            sma_inf / sma_t)\n",
    "\n",
    "        var_t = tf.where(sma_t >= 5.0, r_t * m_corr_t / (v_corr_t + epsilon_t), m_corr_t)\n",
    "\n",
    "        if self._initial_weight_decay > 0.0:\n",
    "            var_t += self._get_hyper('weight_decay', var_dtype) * var\n",
    "\n",
    "        var_update = self._resource_scatter_add(var, indices, tf.gather(-lr_t * var_t, indices))\n",
    "\n",
    "        updates = [var_update, m_t, v_t]\n",
    "        if self.amsgrad:\n",
    "            updates.append(vhat_t)\n",
    "        return control_flow_ops.group(*updates)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(RAdam, self).get_config()\n",
    "        config.update({\n",
    "            'learning_rate': self._serialize_hyperparameter('learning_rate'),\n",
    "            'beta_1': self._serialize_hyperparameter('beta_1'),\n",
    "            'beta_2': self._serialize_hyperparameter('beta_2'),\n",
    "            'decay': self._serialize_hyperparameter('decay'),\n",
    "            'weight_decay': self._serialize_hyperparameter('weight_decay'),\n",
    "            'epsilon': self.epsilon,\n",
    "            'amsgrad': self.amsgrad,\n",
    "            'total_steps': self._serialize_hyperparameter('total_steps'),\n",
    "            'warmup_proportion': self._serialize_hyperparameter('warmup_proportion'),\n",
    "            'min_lr': self._serialize_hyperparameter('min_lr'),\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv').set_index('id')\n",
    "test = pd.read_csv('data/test.csv').set_index('id')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:데이콘/컴퓨터 비전 학습 경진대회/85percent.ipynb
   "execution_count": 5,
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
>>>>>>> parent of 9612ab3... 14-Sep-2020:데이콘/컴퓨터 비전 학습 경진대회/새 폴더/85percent.ipynb
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      digit letter  0  1  2  3  4  5  6  7  ...  774  775  776  777  778  779  \\\nid                                          ...                                 \n1         5      L  1  1  1  4  3  0  0  4  ...    2    1    0    1    2    4   \n2         0      B  0  4  0  0  4  1  1  1  ...    0    3    0    1    4    1   \n3         4      L  1  1  2  2  1  1  1  0  ...    3    3    3    0    2    0   \n4         9      D  1  2  0  2  0  4  0  3  ...    3    3    2    0    1    4   \n5         6      A  3  0  2  4  0  3  0  4  ...    4    4    3    2    1    3   \n...     ...    ... .. .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...  ...   \n2044      6      V  2  4  3  4  2  4  4  1  ...    0    2    2    0    0    1   \n2045      1      L  3  2  2  1  1  4  0  1  ...    2    3    4    2    1    2   \n2046      9      A  4  0  4  0  2  4  4  4  ...    2    3    1    1    3    4   \n2047      0      Z  2  3  3  0  3  0  4  3  ...    2    3    1    1    0    4   \n2048      5      Z  4  2  2  1  3  0  0  0  ...    4    2    4    0    4    3   \n\n      780  781  782  783  \nid                        \n1       4    4    3    4  \n2       4    2    1    2  \n3       3    0    2    2  \n4       0    0    1    1  \n5       4    3    1    2  \n...   ...  ...  ...  ...  \n2044    3    1    4    0  \n2045    3    4    1    1  \n2046    2    2    0    0  \n2047    1    4    3    1  \n2048    2    4    3    4  \n\n[2048 rows x 786 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>digit</th>\n      <th>letter</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>...</th>\n      <th>774</th>\n      <th>775</th>\n      <th>776</th>\n      <th>777</th>\n      <th>778</th>\n      <th>779</th>\n      <th>780</th>\n      <th>781</th>\n      <th>782</th>\n      <th>783</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>L</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>...</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>B</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>L</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9</td>\n      <td>D</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>3</td>\n      <td>...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>A</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>4</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>4</td>\n      <td>...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2044</th>\n      <td>6</td>\n      <td>V</td>\n      <td>2</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2045</th>\n      <td>1</td>\n      <td>L</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2046</th>\n      <td>9</td>\n      <td>A</td>\n      <td>4</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>2</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>...</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2047</th>\n      <td>0</td>\n      <td>Z</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>4</td>\n      <td>3</td>\n      <td>...</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2048</th>\n      <td>5</td>\n      <td>Z</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2</td>\n      <td>4</td>\n      <td>0</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>2048 rows × 786 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = train.copy()\n",
    "# copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, validation_data = train_test_split(copy, test_size = 0.2, shuffle = False, random_state = 1004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data\n",
    "# validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = train_data['digit']\n",
    "y_val = validation_data['digit']\n",
    "y_val = y_val.to_frame()\n",
    "ytrain = ytrain.to_frame()\n",
    "# ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = train_data.drop(['digit', 'letter'], axis = 1)\n",
    "x_val = validation_data.drop(['digit', 'letter'], axis = 1)\n",
    "test = test.drop(['letter'], axis = 1)\n",
    "# xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # digit  디코딩\n",
    "# decoding = np.argmax(onehot_ytrain, axis=1).reshape(-1,1)\n",
    "# decoding = pd.DataFrame(decoding, columns = ['digit'])\n",
    "# decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
<<<<<<< HEAD:데이콘/컴퓨터 비전 학습 경진대회/85percent.ipynb
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# onehot\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "onehot_letter = encoder.fit_transform(letter)\n",
    "onehot_letter_val = encoder.fit_transform(letter_val)\n",
    "onehot_test_letter = encoder.fit_transform(test_letter)\n",
    "\n",
    "\n",
    "onehot_ytrain = tf.keras.utils.to_categorical(ytrain, 10)\n",
    "onehot_y_val = tf.keras.utils.to_categorical(y_val, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
=======
>>>>>>> parent of 9612ab3... 14-Sep-2020:데이콘/컴퓨터 비전 학습 경진대회/새 폴더/85percent.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = np.array(xtrain)\n",
    "ytrain = np.array(ytrain)\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)\n",
    "test = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "xtrain.shape = (1638, 784)\nytrain.shape = (1638, 1)\nx_val.shape = (410, 784)\ny_val.shape = (410, 1)\ntest.shape = (20480, 784)\n"
    }
   ],
   "source": [
    "print('xtrain.shape = {}'.format(xtrain.shape))\n",
    "print('ytrain.shape = {}'.format(ytrain.shape))\n",
    "print('x_val.shape = {}'.format(x_val.shape))\n",
    "print('y_val.shape = {}'.format(y_val.shape))\n",
    "print('test.shape = {}'.format(test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape\n",
    "xtrain = xtrain.reshape((1638, 28, 28, 1))\n",
    "x_val = x_val.reshape((410, 28, 28, 1))\n",
    "test = test.reshape((20480, 28, 28, 1))\n",
    "\n",
    "# onehot\n",
    "onehot_ytrain = tf.keras.utils.to_categorical(ytrain, 10)\n",
    "onehot_y_val = tf.keras.utils.to_categorical(y_val, 10)\n",
    "\n",
    "# float32\n",
    "xtrain = xtrain.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "test = test.astype('float32')\n",
    "onehot_ytrain = onehot_ytrain.astype('float32')\n",
    "\n",
    "# /255\n",
    "test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "xtrain.shape = (1638, 28, 28, 1)\nonehot_ytrain.shape = (1638, 10)\nx_val.shape = (410, 28, 28, 1)\nonehot_y_val.shape = (410, 10)\ntest.shape = (20480, 28, 28, 1)\n"
    }
   ],
   "source": [
    "print('xtrain.shape = {}'.format(xtrain.shape))\n",
    "print('onehot_ytrain.shape = {}'.format(onehot_ytrain.shape))\n",
    "print('x_val.shape = {}'.format(x_val.shape))\n",
    "print('onehot_y_val.shape = {}'.format(onehot_y_val.shape))\n",
    "print('test.shape = {}'.format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoding['digit'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIMIZER = tf.keras.optimizers.SGD(lr=0.01)\n",
    "OPTIMIZER = tf.keras.optimizers.Adam(lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    width_shift_range = 5,\n",
    "    height_shift_range = 5,\n",
    "    rotation_range = 10,\n",
    "    zoom_range = 0.05\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    ")\n",
    "\n",
    "train_datagen.fit(xtrain)\n",
    "validation_datagen.fit(x_val)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:데이콘/컴퓨터 비전 학습 경진대회/85percent.ipynb
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = Input(shape = (28, 28, 1), dtype = 'float32', name = 'image')\n",
    "letter_input = Input(shape = (1, 26), dtype = 'float32', name = 'letter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
=======
   "execution_count": 18,
>>>>>>> parent of 9612ab3... 14-Sep-2020:데이콘/컴퓨터 비전 학습 경진대회/새 폴더/85percent.ipynb
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nzero_padding2d (ZeroPadding2 (None, 30, 30, 1)         0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 30, 30, 128)       3328      \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 30, 30, 128)       147584    \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 15, 15, 128)       0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 15, 15, 256)       295168    \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 15, 15, 256)       590080    \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 7, 7, 256)         0         \n_________________________________________________________________\ndropout (Dropout)            (None, 7, 7, 256)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 12544)             0         \n_________________________________________________________________\ndense (Dense)                (None, 256)               3211520   \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                2570      \n=================================================================\nTotal params: 4,250,250\nTrainable params: 4,250,250\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "\n",
    "def Create_model():\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        keras.layers.ZeroPadding2D((1, 1), input_shape = (28, 28, 1)),\n",
    "        keras.layers.Conv2D(128, (5, 5), activation = 'relu', padding = 'same'),\n",
    "        # keras.layers.BatchNormalization(),\n",
    "        # keras.layers.ZeroPadding2D((1, 1)),\n",
    "        keras.layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same'),\n",
    "        keras.layers.MaxPooling2D(2, 2),\n",
    "        # keras.layers.BatchNormalization(),\n",
    "        # keras.layers.ZeroPadding2D((1, 1)),\n",
    "        keras.layers.Conv2D(256, (3, 3), activation = 'relu', padding = 'same'),\n",
    "        # keras.layers.BatchNormalization(),\n",
    "        # keras.layers.ZeroPadding2D((1, 1)),\n",
    "        keras.layers.Conv2D(256, (3, 3), activation = 'relu', padding = 'same'),\n",
    "        keras.layers.MaxPooling2D(2, 2),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Flatten(),\n",
    "        # keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(256, activation = 'relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        # keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(10, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(RAdam(),\n",
    "                  loss = 'categorical_crossentropy',\n",
    "                  metrics = [\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = Create_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:데이콘/컴퓨터 비전 학습 경진대회/85percent.ipynb
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(RAdam(learning_rate = 0.001),\n",
    "                loss = 'categorical_crossentropy',\n",
    "                metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# def Create_model():\n",
    "\n",
    "#     model = tf.keras.models.Sequential([\n",
    "#         keras.layers.ZeroPadding2D((1, 1), input_shape = (28, 28, 1)),\n",
    "#         keras.layers.Conv2D(128, (5, 5), activation = 'relu', padding = 'same'),\n",
    "#         # keras.layers.BatchNormalization(),\n",
    "#         # keras.layers.ZeroPadding2D((1, 1)),\n",
    "#         keras.layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same'),\n",
    "#         keras.layers.MaxPooling2D(2, 2),\n",
    "#         # keras.layers.BatchNormalization(),\n",
    "#         # keras.layers.ZeroPadding2D((1, 1)),\n",
    "#         keras.layers.Conv2D(256, (3, 3), activation = 'relu', padding = 'same'),\n",
    "#         # keras.layers.BatchNormalization(),\n",
    "#         # keras.layers.ZeroPadding2D((1, 1)),\n",
    "#         keras.layers.Conv2D(256, (3, 3), activation = 'relu', padding = 'same'),\n",
    "#         keras.layers.MaxPooling2D(2, 2),\n",
    "#         keras.layers.Dropout(0.2),\n",
    "#         keras.layers.Flatten(),\n",
    "#         # keras.layers.BatchNormalization(),\n",
    "#         keras.layers.Dense(256, activation = 'relu'),\n",
    "#         keras.layers.Dropout(0.5),\n",
    "#         # keras.layers.BatchNormalization(),\n",
    "#         keras.layers.Dense(10, activation = 'softmax')\n",
    "#     ])\n",
    "\n",
    "#     model.compile(RAdam(),\n",
    "#                   loss = 'categorical_crossentropy',\n",
    "#                   metrics = [\"accuracy\"])\n",
    "\n",
    "#     return model\n",
    "\n",
    "# model = Create_model()\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
=======
   "execution_count": 19,
>>>>>>> parent of 9612ab3... 14-Sep-2020:데이콘/컴퓨터 비전 학습 경진대회/새 폴더/85percent.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "EarlyStopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', patience = 10)\n",
    "ModelCheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath = 'best_model.h5', monitor = 'val_loss', save_weights_only = True, save_best_only = True)\n",
    "ReduceLROnPlateau = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', patience = 5, factor = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:데이콘/컴퓨터 비전 학습 경진대회/85percent.ipynb
   "execution_count": 24,
=======
   "execution_count": 20,
>>>>>>> parent of 9612ab3... 14-Sep-2020:데이콘/컴퓨터 비전 학습 경진대회/새 폴더/85percent.ipynb
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
<<<<<<< HEAD:데이콘/컴퓨터 비전 학습 경진대회/85percent.ipynb
     "text": "Epoch 1/150\n103/102 [==============================] - 74s 716ms/step - loss: 3.2518 - accuracy: 0.1538 - val_loss: 2.3050 - val_accuracy: 0.1073\nEpoch 2/150\n103/102 [==============================] - 71s 687ms/step - loss: 2.8843 - accuracy: 0.2082 - val_loss: 2.3410 - val_accuracy: 0.1073\nEpoch 3/150\n 49/102 [=============>................] - ETA: 35s - loss: 2.5512 - accuracy: 0.2194"
=======
     "text": "Epoch 1/100\n52/51 [==============================] - 17s 327ms/step - loss: 2.2997 - accuracy: 0.1154 - val_loss: 2.2994 - val_accuracy: 0.1220 - lr: 0.0010\nEpoch 2/100\n52/51 [==============================] - 16s 315ms/step - loss: 2.2818 - accuracy: 0.1319 - val_loss: 2.2377 - val_accuracy: 0.1024 - lr: 0.0010\nEpoch 3/100\n52/51 [==============================] - 17s 321ms/step - loss: 2.2152 - accuracy: 0.1795 - val_loss: 2.1377 - val_accuracy: 0.3268 - lr: 0.0010\nEpoch 4/100\n52/51 [==============================] - 16s 311ms/step - loss: 2.0925 - accuracy: 0.2564 - val_loss: 1.8655 - val_accuracy: 0.3098 - lr: 0.0010\nEpoch 5/100\n52/51 [==============================] - 17s 323ms/step - loss: 1.9763 - accuracy: 0.2827 - val_loss: 1.6154 - val_accuracy: 0.3927 - lr: 0.0010\nEpoch 6/100\n52/51 [==============================] - 18s 337ms/step - loss: 1.8459 - accuracy: 0.3419 - val_loss: 1.5013 - val_accuracy: 0.5195 - lr: 0.0010\nEpoch 7/100\n52/51 [==============================] - 19s 361ms/step - loss: 1.7611 - accuracy: 0.3980 - val_loss: 1.4651 - val_accuracy: 0.5244 - lr: 0.0010\nEpoch 8/100\n52/51 [==============================] - 17s 318ms/step - loss: 1.6496 - accuracy: 0.4280 - val_loss: 1.2779 - val_accuracy: 0.5805 - lr: 0.0010\nEpoch 9/100\n52/51 [==============================] - 16s 314ms/step - loss: 1.5308 - accuracy: 0.4701 - val_loss: 1.2168 - val_accuracy: 0.5756 - lr: 0.0010\nEpoch 10/100\n52/51 [==============================] - 16s 314ms/step - loss: 1.4259 - accuracy: 0.5085 - val_loss: 1.2438 - val_accuracy: 0.5585 - lr: 0.0010\nEpoch 11/100\n52/51 [==============================] - 17s 319ms/step - loss: 1.4365 - accuracy: 0.5195 - val_loss: 1.0779 - val_accuracy: 0.6366 - lr: 0.0010\nEpoch 12/100\n52/51 [==============================] - 18s 350ms/step - loss: 1.2891 - accuracy: 0.5629 - val_loss: 0.9340 - val_accuracy: 0.6878 - lr: 0.0010\nEpoch 13/100\n52/51 [==============================] - 17s 322ms/step - loss: 1.2019 - accuracy: 0.5800 - val_loss: 0.9462 - val_accuracy: 0.6659 - lr: 0.0010\nEpoch 14/100\n52/51 [==============================] - 16s 314ms/step - loss: 1.1432 - accuracy: 0.6062 - val_loss: 0.8226 - val_accuracy: 0.7122 - lr: 0.0010\nEpoch 15/100\n52/51 [==============================] - 17s 332ms/step - loss: 1.1565 - accuracy: 0.6087 - val_loss: 0.9089 - val_accuracy: 0.6829 - lr: 0.0010\nEpoch 16/100\n52/51 [==============================] - 17s 326ms/step - loss: 1.0608 - accuracy: 0.6392 - val_loss: 0.9906 - val_accuracy: 0.6366 - lr: 0.0010\nEpoch 17/100\n52/51 [==============================] - 18s 348ms/step - loss: 1.0547 - accuracy: 0.6532 - val_loss: 0.8834 - val_accuracy: 0.6976 - lr: 0.0010\nEpoch 18/100\n52/51 [==============================] - 17s 326ms/step - loss: 0.9878 - accuracy: 0.6746 - val_loss: 0.9134 - val_accuracy: 0.6829 - lr: 0.0010\nEpoch 19/100\n52/51 [==============================] - 17s 330ms/step - loss: 0.9800 - accuracy: 0.6703 - val_loss: 0.8619 - val_accuracy: 0.7049 - lr: 0.0010\nEpoch 20/100\n52/51 [==============================] - 17s 327ms/step - loss: 0.8870 - accuracy: 0.7155 - val_loss: 0.6864 - val_accuracy: 0.7683 - lr: 1.0000e-04\nEpoch 21/100\n52/51 [==============================] - 16s 313ms/step - loss: 0.8207 - accuracy: 0.7143 - val_loss: 0.6924 - val_accuracy: 0.7610 - lr: 1.0000e-04\nEpoch 22/100\n52/51 [==============================] - 17s 325ms/step - loss: 0.7630 - accuracy: 0.7497 - val_loss: 0.6714 - val_accuracy: 0.7683 - lr: 1.0000e-04\nEpoch 23/100\n52/51 [==============================] - 16s 310ms/step - loss: 0.7914 - accuracy: 0.7399 - val_loss: 0.6708 - val_accuracy: 0.7732 - lr: 1.0000e-04\nEpoch 24/100\n52/51 [==============================] - 16s 311ms/step - loss: 0.7610 - accuracy: 0.7479 - val_loss: 0.6496 - val_accuracy: 0.7683 - lr: 1.0000e-04\nEpoch 25/100\n52/51 [==============================] - 16s 313ms/step - loss: 0.7304 - accuracy: 0.7521 - val_loss: 0.6495 - val_accuracy: 0.7634 - lr: 1.0000e-04\nEpoch 26/100\n52/51 [==============================] - 16s 308ms/step - loss: 0.7387 - accuracy: 0.7527 - val_loss: 0.6728 - val_accuracy: 0.7610 - lr: 1.0000e-04\nEpoch 27/100\n52/51 [==============================] - 16s 309ms/step - loss: 0.7417 - accuracy: 0.7595 - val_loss: 0.6947 - val_accuracy: 0.7585 - lr: 1.0000e-04\nEpoch 28/100\n52/51 [==============================] - 17s 318ms/step - loss: 0.7286 - accuracy: 0.7558 - val_loss: 0.6717 - val_accuracy: 0.7561 - lr: 1.0000e-04\nEpoch 29/100\n52/51 [==============================] - 16s 315ms/step - loss: 0.6922 - accuracy: 0.7692 - val_loss: 0.6819 - val_accuracy: 0.7537 - lr: 1.0000e-04\nEpoch 30/100\n52/51 [==============================] - 17s 331ms/step - loss: 0.6980 - accuracy: 0.7656 - val_loss: 0.6680 - val_accuracy: 0.7659 - lr: 1.0000e-04\nEpoch 31/100\n52/51 [==============================] - 17s 329ms/step - loss: 0.6892 - accuracy: 0.7650 - val_loss: 0.6672 - val_accuracy: 0.7683 - lr: 1.0000e-05\nEpoch 32/100\n52/51 [==============================] - 16s 314ms/step - loss: 0.6733 - accuracy: 0.7747 - val_loss: 0.6416 - val_accuracy: 0.7756 - lr: 1.0000e-05\nEpoch 33/100\n52/51 [==============================] - 17s 322ms/step - loss: 0.7127 - accuracy: 0.7521 - val_loss: 0.6412 - val_accuracy: 0.7756 - lr: 1.0000e-05\nEpoch 34/100\n52/51 [==============================] - 16s 314ms/step - loss: 0.6837 - accuracy: 0.7796 - val_loss: 0.6471 - val_accuracy: 0.7659 - lr: 1.0000e-05\nEpoch 35/100\n52/51 [==============================] - 17s 318ms/step - loss: 0.6860 - accuracy: 0.7753 - val_loss: 0.6413 - val_accuracy: 0.7756 - lr: 1.0000e-05\nEpoch 36/100\n52/51 [==============================] - 18s 340ms/step - loss: 0.6562 - accuracy: 0.7808 - val_loss: 0.6449 - val_accuracy: 0.7732 - lr: 1.0000e-05\nEpoch 37/100\n52/51 [==============================] - 18s 337ms/step - loss: 0.6671 - accuracy: 0.7668 - val_loss: 0.6576 - val_accuracy: 0.7561 - lr: 1.0000e-05\nEpoch 38/100\n52/51 [==============================] - 17s 319ms/step - loss: 0.6841 - accuracy: 0.7717 - val_loss: 0.6434 - val_accuracy: 0.7683 - lr: 1.0000e-05\nEpoch 39/100\n52/51 [==============================] - 17s 324ms/step - loss: 0.6497 - accuracy: 0.7759 - val_loss: 0.6436 - val_accuracy: 0.7732 - lr: 1.0000e-06\nEpoch 40/100\n52/51 [==============================] - 17s 327ms/step - loss: 0.6468 - accuracy: 0.7821 - val_loss: 0.6437 - val_accuracy: 0.7732 - lr: 1.0000e-06\nEpoch 41/100\n52/51 [==============================] - 17s 322ms/step - loss: 0.6734 - accuracy: 0.7680 - val_loss: 0.6431 - val_accuracy: 0.7732 - lr: 1.0000e-06\nEpoch 42/100\n52/51 [==============================] - 17s 321ms/step - loss: 0.6725 - accuracy: 0.7821 - val_loss: 0.6439 - val_accuracy: 0.7732 - lr: 1.0000e-06\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x261d475c0c8>"
     },
     "metadata": {},
     "execution_count": 20
>>>>>>> parent of 9612ab3... 14-Sep-2020:데이콘/컴퓨터 비전 학습 경진대회/새 폴더/85percent.ipynb
    }
   ],
   "source": [
    "# log_dir = \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard = tf.keras.callbacks.TensorBoard(log_dir = log_dir, histogram_freq = 1)\n",
    "# model.fit_generator(\n",
    "#     datagen.flow(xtrain, ytrain1, batch_size = 32),\n",
    "#     epochs = 150,\n",
    "#     verbose = 1,\n",
    "#     callbacks = [tensorboard, checkpoint]\n",
    "# )\n",
    "model.fit(train_datagen.flow(xtrain, onehot_ytrain),  \n",
    "          epochs = 100,\n",
    "          steps_per_epoch = len(xtrain) / 32,\n",
    "          verbose = 1,\n",
    "          validation_data = validation_datagen.flow(x_val, onehot_y_val),\n",
    "          validation_steps = len(x_val) / 32,\n",
    "          callbacks = [ModelCheckpoint, EarlyStopping]\n",
    ")\n",
    "\n",
    "# %tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Tensorboard Link](http://localhost:6006)  \n",
    "71/71 [==============================] - 13s 181ms/step - loss: 0.0737 - accuracy: 0.9756 - val_loss: 0.5013 - val_accuracy: 0.8244"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-f526e924d570>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# digit  디코딩\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdecoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdecoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'digit'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdecoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m     87\u001b[0m           method.__name__))\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1266\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1268\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1269\u001b[0m             \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1270\u001b[0m             \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    616\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test, batch_size=32)\n",
    "# digit  디코딩\n",
    "decoding = np.argmax(y_pred, axis=1).reshape(-1,1)\n",
    "decoding = pd.DataFrame(decoding, columns = ['digit'])\n",
    "decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "sorted(decoding['digit'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       digit\n0          6\n1          9\n2          8\n3          0\n4          3\n...      ...\n20475      9\n20476      1\n20477      6\n20478      8\n20479      0\n\n[20480 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>digit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20475</th>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>20476</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20477</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>20478</th>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>20479</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>20480 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "model.load_weights('best_model.h5')\n",
    "y_pred = model.predict(test, batch_size=26)\n",
    "# digit  디코딩\n",
    "decoding = np.argmax(y_pred, axis=1).reshape(-1,1)\n",
    "decoding = pd.DataFrame(decoding, columns = ['digit'])\n",
    "decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          id  digit\n0       2049      6\n1       2050      9\n2       2051      8\n3       2052      0\n4       2053      3\n...      ...    ...\n20475  22524      9\n20476  22525      1\n20477  22526      6\n20478  22527      8\n20479  22528      0\n\n[20480 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>digit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2049</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2050</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2051</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2052</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2053</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20475</th>\n      <td>22524</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>20476</th>\n      <td>22525</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20477</th>\n      <td>22526</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>20478</th>\n      <td>22527</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>20479</th>\n      <td>22528</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>20480 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "sub = pd.read_csv('data/submission.csv')\n",
    "sub = sub.drop(['digit'], axis = 1)\n",
    "sub = pd.concat([sub, decoding], axis = 1)\n",
    "sub.to_csv('sub.csv', index = False, encoding = 'utf-8')\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ]
}