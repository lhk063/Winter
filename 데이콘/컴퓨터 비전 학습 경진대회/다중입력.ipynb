{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599971273370",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import keras\n",
    "from keras import layers, Input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "#from tensorflow.keras import datasets, layers, models, optimizers\n",
    "%load_ext tensorboard\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_radam import RAdam\n",
    "from tensorflow.python.keras.optimizer_v2.optimizer_v2 import OptimizerV2\n",
    "from tensorflow.python import ops, math_ops, state_ops, control_flow_ops\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "__all__ = ['RAdam']\n",
    "\n",
    "\n",
    "class RAdam(OptimizerV2):\n",
    "    \"\"\"RAdam optimizer.\n",
    "    According to the paper\n",
    "    [On The Variance Of The Adaptive Learning Rate And Beyond](https://arxiv.org/pdf/1908.03265v1.pdf).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 learning_rate=0.001,\n",
    "                 beta_1=0.9,\n",
    "                 beta_2=0.999,\n",
    "                 epsilon=1e-7,\n",
    "                 weight_decay=0.,\n",
    "                 amsgrad=False,\n",
    "                 total_steps=0,\n",
    "                 warmup_proportion=0.1,\n",
    "                 min_lr=0.,\n",
    "                 name='RAdam',\n",
    "                 **kwargs):\n",
    "        r\"\"\"Construct a new Adam optimizer.\n",
    "        Args:\n",
    "            learning_rate: A Tensor or a floating point value.    The learning rate.\n",
    "            beta_1: A float value or a constant float tensor. The exponential decay\n",
    "                rate for the 1st moment estimates.\n",
    "            beta_2: A float value or a constant float tensor. The exponential decay\n",
    "                rate for the 2nd moment estimates.\n",
    "            epsilon: A small constant for numerical stability. This epsilon is\n",
    "                \"epsilon hat\" in the Kingma and Ba paper (in the formula just before\n",
    "                Section 2.1), not the epsilon in Algorithm 1 of the paper.\n",
    "            weight_decay: A floating point value. Weight decay for each param.\n",
    "            amsgrad: boolean. Whether to apply AMSGrad variant of this algorithm from\n",
    "                the paper \"On the Convergence of Adam and beyond\".\n",
    "            total_steps: An integer. Total number of training steps.\n",
    "                Enable warmup by setting a positive value.\n",
    "            warmup_proportion: A floating point value. The proportion of increasing steps.\n",
    "            min_lr: A floating point value. Minimum learning rate after warmup.\n",
    "            name: Optional name for the operations created when applying gradients.\n",
    "                Defaults to \"Adam\".    @compatibility(eager) When eager execution is\n",
    "                enabled, `learning_rate`, `beta_1`, `beta_2`, and `epsilon` can each be\n",
    "                a callable that takes no arguments and returns the actual value to use.\n",
    "                This can be useful for changing these values across different\n",
    "                invocations of optimizer functions. @end_compatibility\n",
    "            **kwargs: keyword arguments. Allowed to be {`clipnorm`, `clipvalue`, `lr`,\n",
    "                `decay`}. `clipnorm` is clip gradients by norm; `clipvalue` is clip\n",
    "                gradients by value, `decay` is included for backward compatibility to\n",
    "                allow time inverse decay of learning rate. `lr` is included for backward\n",
    "                compatibility, recommended to use `learning_rate` instead.\n",
    "        \"\"\"\n",
    "\n",
    "        super(RAdam, self).__init__(name, **kwargs)\n",
    "        self._set_hyper('learning_rate', kwargs.get('lr', learning_rate))\n",
    "        self._set_hyper('beta_1', beta_1)\n",
    "        self._set_hyper('beta_2', beta_2)\n",
    "        self._set_hyper('decay', self._initial_decay)\n",
    "        self._set_hyper('weight_decay', weight_decay)\n",
    "        self._set_hyper('total_steps', float(total_steps))\n",
    "        self._set_hyper('warmup_proportion', warmup_proportion)\n",
    "        self._set_hyper('min_lr', min_lr)\n",
    "        self.epsilon = epsilon or K.epsilon()\n",
    "        self.amsgrad = amsgrad\n",
    "        self._initial_weight_decay = weight_decay\n",
    "        self._initial_total_steps = total_steps\n",
    "\n",
    "    def _create_slots(self, var_list):\n",
    "        for var in var_list:\n",
    "            self.add_slot(var, 'm')\n",
    "        for var in var_list:\n",
    "            self.add_slot(var, 'v')\n",
    "        if self.amsgrad:\n",
    "            for var in var_list:\n",
    "                self.add_slot(var, 'vhat')\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        params = self.weights\n",
    "        num_vars = int((len(params) - 1) / 2)\n",
    "        if len(weights) == 3 * num_vars + 1:\n",
    "            weights = weights[:len(params)]\n",
    "        super(RAdam, self).set_weights(weights)\n",
    "\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        lr_t = self._decayed_lr(var_dtype)\n",
    "        m = self.get_slot(var, 'm')\n",
    "        v = self.get_slot(var, 'v')\n",
    "        beta_1_t = self._get_hyper('beta_1', var_dtype)\n",
    "        beta_2_t = self._get_hyper('beta_2', var_dtype)\n",
    "        epsilon_t = ops.convert_to_tensor(self.epsilon, var_dtype)\n",
    "        local_step = math_ops.cast(self.iterations + 1, var_dtype)\n",
    "        beta_1_power = math_ops.pow(beta_1_t, local_step)\n",
    "        beta_2_power = math_ops.pow(beta_2_t, local_step)\n",
    "\n",
    "        if self._initial_total_steps > 0:\n",
    "            total_steps = self._get_hyper('total_steps', var_dtype)\n",
    "            warmup_steps = total_steps * self._get_hyper('warmup_proportion', var_dtype)\n",
    "            min_lr = self._get_hyper('min_lr', var_dtype)\n",
    "            decay_steps = K.maximum(total_steps - warmup_steps, 1)\n",
    "            decay_rate = (min_lr - lr_t) / decay_steps\n",
    "            lr_t = tf.where(\n",
    "                local_step <= warmup_steps,\n",
    "                lr_t * (local_step / warmup_steps),\n",
    "                lr_t + decay_rate * K.minimum(local_step - warmup_steps, decay_steps),\n",
    "            )\n",
    "\n",
    "        sma_inf = 2.0 / (1.0 - beta_2_t) - 1.0\n",
    "        sma_t = sma_inf - 2.0 * local_step * beta_2_power / (1.0 - beta_2_power)\n",
    "\n",
    "        m_t = state_ops.assign(m,\n",
    "                               beta_1_t * m + (1.0 - beta_1_t) * grad,\n",
    "                               use_locking=self._use_locking)\n",
    "        m_corr_t = m_t / (1.0 - beta_1_power)\n",
    "\n",
    "        v_t = state_ops.assign(v,\n",
    "                               beta_2_t * v + (1.0 - beta_2_t) * math_ops.square(grad),\n",
    "                               use_locking=self._use_locking)\n",
    "        if self.amsgrad:\n",
    "            vhat = self.get_slot(var, 'vhat')\n",
    "            vhat_t = state_ops.assign(vhat,\n",
    "                                      math_ops.maximum(vhat, v_t),\n",
    "                                      use_locking=self._use_locking)\n",
    "            v_corr_t = math_ops.sqrt(vhat_t / (1.0 - beta_2_power))\n",
    "        else:\n",
    "            vhat_t = None\n",
    "            v_corr_t = math_ops.sqrt(v_t / (1.0 - beta_2_power))\n",
    "\n",
    "        r_t = math_ops.sqrt((sma_t - 4.0) / (sma_inf - 4.0) *\n",
    "                            (sma_t - 2.0) / (sma_inf - 2.0) *\n",
    "                            sma_inf / sma_t)\n",
    "\n",
    "        var_t = tf.where(sma_t >= 5.0, r_t * m_corr_t / (v_corr_t + epsilon_t), m_corr_t)\n",
    "\n",
    "        if self._initial_weight_decay > 0.0:\n",
    "            var_t += self._get_hyper('weight_decay', var_dtype) * var\n",
    "\n",
    "        var_update = state_ops.assign_sub(var,\n",
    "                                          lr_t * var_t,\n",
    "                                          use_locking=self._use_locking)\n",
    "\n",
    "        updates = [var_update, m_t, v_t]\n",
    "        if self.amsgrad:\n",
    "            updates.append(vhat_t)\n",
    "        return control_flow_ops.group(*updates)\n",
    "\n",
    "    def _resource_apply_sparse(self, grad, var, indices):\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        lr_t = self._decayed_lr(var_dtype)\n",
    "        beta_1_t = self._get_hyper('beta_1', var_dtype)\n",
    "        beta_2_t = self._get_hyper('beta_2', var_dtype)\n",
    "        epsilon_t = ops.convert_to_tensor(self.epsilon, var_dtype)\n",
    "        local_step = math_ops.cast(self.iterations + 1, var_dtype)\n",
    "        beta_1_power = math_ops.pow(beta_1_t, local_step)\n",
    "        beta_2_power = math_ops.pow(beta_2_t, local_step)\n",
    "\n",
    "        if self._initial_total_steps > 0:\n",
    "            total_steps = self._get_hyper('total_steps', var_dtype)\n",
    "            warmup_steps = total_steps * self._get_hyper('warmup_proportion', var_dtype)\n",
    "            min_lr = self._get_hyper('min_lr', var_dtype)\n",
    "            decay_steps = K.maximum(total_steps - warmup_steps, 1)\n",
    "            decay_rate = (min_lr - lr_t) / decay_steps\n",
    "            lr_t = tf.where(\n",
    "                local_step <= warmup_steps,\n",
    "                lr_t * (local_step / warmup_steps),\n",
    "                lr_t + decay_rate * K.minimum(local_step - warmup_steps, decay_steps),\n",
    "            )\n",
    "\n",
    "        sma_inf = 2.0 / (1.0 - beta_2_t) - 1.0\n",
    "        sma_t = sma_inf - 2.0 * local_step * beta_2_power / (1.0 - beta_2_power)\n",
    "\n",
    "        m = self.get_slot(var, 'm')\n",
    "        m_scaled_g_values = grad * (1 - beta_1_t)\n",
    "        m_t = state_ops.assign(m, m * beta_1_t, use_locking=self._use_locking)\n",
    "        with ops.control_dependencies([m_t]):\n",
    "            m_t = self._resource_scatter_add(m, indices, m_scaled_g_values)\n",
    "        m_corr_t = m_t / (1.0 - beta_1_power)\n",
    "\n",
    "        v = self.get_slot(var, 'v')\n",
    "        v_scaled_g_values = (grad * grad) * (1 - beta_2_t)\n",
    "        v_t = state_ops.assign(v, v * beta_2_t, use_locking=self._use_locking)\n",
    "        with ops.control_dependencies([v_t]):\n",
    "            v_t = self._resource_scatter_add(v, indices, v_scaled_g_values)\n",
    "\n",
    "        if self.amsgrad:\n",
    "            vhat = self.get_slot(var, 'vhat')\n",
    "            vhat_t = state_ops.assign(vhat,\n",
    "                                      math_ops.maximum(vhat, v_t),\n",
    "                                      use_locking=self._use_locking)\n",
    "            v_corr_t = math_ops.sqrt(vhat_t / (1.0 - beta_2_power))\n",
    "        else:\n",
    "            vhat_t = None\n",
    "            v_corr_t = math_ops.sqrt(v_t / (1.0 - beta_2_power))\n",
    "\n",
    "        r_t = math_ops.sqrt((sma_t - 4.0) / (sma_inf - 4.0) *\n",
    "                            (sma_t - 2.0) / (sma_inf - 2.0) *\n",
    "                            sma_inf / sma_t)\n",
    "\n",
    "        var_t = tf.where(sma_t >= 5.0, r_t * m_corr_t / (v_corr_t + epsilon_t), m_corr_t)\n",
    "\n",
    "        if self._initial_weight_decay > 0.0:\n",
    "            var_t += self._get_hyper('weight_decay', var_dtype) * var\n",
    "\n",
    "        var_update = self._resource_scatter_add(var, indices, tf.gather(-lr_t * var_t, indices))\n",
    "\n",
    "        updates = [var_update, m_t, v_t]\n",
    "        if self.amsgrad:\n",
    "            updates.append(vhat_t)\n",
    "        return control_flow_ops.group(*updates)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(RAdam, self).get_config()\n",
    "        config.update({\n",
    "            'learning_rate': self._serialize_hyperparameter('learning_rate'),\n",
    "            'beta_1': self._serialize_hyperparameter('beta_1'),\n",
    "            'beta_2': self._serialize_hyperparameter('beta_2'),\n",
    "            'decay': self._serialize_hyperparameter('decay'),\n",
    "            'weight_decay': self._serialize_hyperparameter('weight_decay'),\n",
    "            'epsilon': self.epsilon,\n",
    "            'amsgrad': self.amsgrad,\n",
    "            'total_steps': self._serialize_hyperparameter('total_steps'),\n",
    "            'warmup_proportion': self._serialize_hyperparameter('warmup_proportion'),\n",
    "            'min_lr': self._serialize_hyperparameter('min_lr'),\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv').set_index('id')\n",
    "test = pd.read_csv('data/test.csv').set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      digit letter  0  1  2  3  4  5  6  7  ...  774  775  776  777  778  779  \\\nid                                          ...                                 \n1         5      L  1  1  1  4  3  0  0  4  ...    2    1    0    1    2    4   \n2         0      B  0  4  0  0  4  1  1  1  ...    0    3    0    1    4    1   \n3         4      L  1  1  2  2  1  1  1  0  ...    3    3    3    0    2    0   \n4         9      D  1  2  0  2  0  4  0  3  ...    3    3    2    0    1    4   \n5         6      A  3  0  2  4  0  3  0  4  ...    4    4    3    2    1    3   \n...     ...    ... .. .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...  ...   \n2044      6      V  2  4  3  4  2  4  4  1  ...    0    2    2    0    0    1   \n2045      1      L  3  2  2  1  1  4  0  1  ...    2    3    4    2    1    2   \n2046      9      A  4  0  4  0  2  4  4  4  ...    2    3    1    1    3    4   \n2047      0      Z  2  3  3  0  3  0  4  3  ...    2    3    1    1    0    4   \n2048      5      Z  4  2  2  1  3  0  0  0  ...    4    2    4    0    4    3   \n\n      780  781  782  783  \nid                        \n1       4    4    3    4  \n2       4    2    1    2  \n3       3    0    2    2  \n4       0    0    1    1  \n5       4    3    1    2  \n...   ...  ...  ...  ...  \n2044    3    1    4    0  \n2045    3    4    1    1  \n2046    2    2    0    0  \n2047    1    4    3    1  \n2048    2    4    3    4  \n\n[2048 rows x 786 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>digit</th>\n      <th>letter</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>...</th>\n      <th>774</th>\n      <th>775</th>\n      <th>776</th>\n      <th>777</th>\n      <th>778</th>\n      <th>779</th>\n      <th>780</th>\n      <th>781</th>\n      <th>782</th>\n      <th>783</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>L</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>...</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>B</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>L</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9</td>\n      <td>D</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>3</td>\n      <td>...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>A</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>4</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>4</td>\n      <td>...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2044</th>\n      <td>6</td>\n      <td>V</td>\n      <td>2</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2045</th>\n      <td>1</td>\n      <td>L</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2046</th>\n      <td>9</td>\n      <td>A</td>\n      <td>4</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>2</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>...</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2047</th>\n      <td>0</td>\n      <td>Z</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>4</td>\n      <td>3</td>\n      <td>...</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2048</th>\n      <td>5</td>\n      <td>Z</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2</td>\n      <td>4</td>\n      <td>0</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>2048 rows × 786 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      digit letter  0  1  2  3  4  5  6  7  ...  774  775  776  777  778  779  \\\nid                                          ...                                 \n1         5      L  1  1  1  4  3  0  0  4  ...    2    1    0    1    2    4   \n2         0      B  0  4  0  0  4  1  1  1  ...    0    3    0    1    4    1   \n3         4      L  1  1  2  2  1  1  1  0  ...    3    3    3    0    2    0   \n4         9      D  1  2  0  2  0  4  0  3  ...    3    3    2    0    1    4   \n5         6      A  3  0  2  4  0  3  0  4  ...    4    4    3    2    1    3   \n...     ...    ... .. .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...  ...   \n2044      6      V  2  4  3  4  2  4  4  1  ...    0    2    2    0    0    1   \n2045      1      L  3  2  2  1  1  4  0  1  ...    2    3    4    2    1    2   \n2046      9      A  4  0  4  0  2  4  4  4  ...    2    3    1    1    3    4   \n2047      0      Z  2  3  3  0  3  0  4  3  ...    2    3    1    1    0    4   \n2048      5      Z  4  2  2  1  3  0  0  0  ...    4    2    4    0    4    3   \n\n      780  781  782  783  \nid                        \n1       4    4    3    4  \n2       4    2    1    2  \n3       3    0    2    2  \n4       0    0    1    1  \n5       4    3    1    2  \n...   ...  ...  ...  ...  \n2044    3    1    4    0  \n2045    3    4    1    1  \n2046    2    2    0    0  \n2047    1    4    3    1  \n2048    2    4    3    4  \n\n[2048 rows x 786 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>digit</th>\n      <th>letter</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>...</th>\n      <th>774</th>\n      <th>775</th>\n      <th>776</th>\n      <th>777</th>\n      <th>778</th>\n      <th>779</th>\n      <th>780</th>\n      <th>781</th>\n      <th>782</th>\n      <th>783</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>L</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>...</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>B</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>L</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9</td>\n      <td>D</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>3</td>\n      <td>...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>A</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>4</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>4</td>\n      <td>...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2044</th>\n      <td>6</td>\n      <td>V</td>\n      <td>2</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2045</th>\n      <td>1</td>\n      <td>L</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2046</th>\n      <td>9</td>\n      <td>A</td>\n      <td>4</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>2</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>...</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2047</th>\n      <td>0</td>\n      <td>Z</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>4</td>\n      <td>3</td>\n      <td>...</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2048</th>\n      <td>5</td>\n      <td>Z</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2</td>\n      <td>4</td>\n      <td>0</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>2048 rows × 786 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "aa = train.copy()\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter = aa['letter']\n",
    "test_letter = test['letter']\n",
    "letter = letter.to_frame()\n",
    "test_letter = test_letter.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      digit\nid         \n1         5\n2         0\n3         4\n4         9\n5         6\n...     ...\n2044      6\n2045      1\n2046      9\n2047      0\n2048      5\n\n[2048 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>digit</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2044</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2045</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2046</th>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2047</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2048</th>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>2048 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "ytrain = aa['digit']\n",
    "ytrain = ytrain.to_frame()\n",
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = aa.drop(['digit', 'letter'], axis = 1)\n",
    "test = test.drop(['letter'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0. 0. 0. ... 0. 0. 0.]\n [1. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 1.]\n [1. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n[[0. 0. 0. ... 0. 0. 0.]\n [0. 1. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [1. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 1.]\n [0. 0. 0. ... 0. 0. 1.]]\n[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 1. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 1. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "onehot_ytrain = encoder.fit_transform(ytrain)\n",
    "onehot_letter = encoder.fit_transform(letter)\n",
    "onehot_test_letter = encoder.fit_transform(test_letter)\n",
    "\n",
    "onehot_ytrain = onehot_ytrain.toarray()\n",
    "onehot_letter = onehot_letter.toarray()\n",
    "onehot_test_letter = onehot_test_letter.toarray()\n",
    "\n",
    "print(onehot_ytrain)\n",
    "print(onehot_letter)\n",
    "print(onehot_test_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      digit\n0         5\n1         0\n2         4\n3         9\n4         6\n...     ...\n2043      6\n2044      1\n2045      9\n2046      0\n2047      5\n\n[2048 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>digit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2043</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2044</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2045</th>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2046</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2047</th>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>2048 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# digit  디코딩\n",
    "decoding = np.argmax(onehot_ytrain, axis=1).reshape(-1,1)\n",
    "decoding = pd.DataFrame(decoding, columns = ['digit'])\n",
    "decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(2048, 784)\n(20480, 784)\n"
    }
   ],
   "source": [
    "# xtrain /= 255.0\n",
    "# test /= 255.0\n",
    "\n",
    "xtrain = np.array(xtrain)\n",
    "test = np.array(test)\n",
    "\n",
    "print(xtrain.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(2048, 784)\n(2048, 10)\n(2048, 26)\n"
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(onehot_ytrain.shape)\n",
    "print(onehot_letter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = xtrain.reshape((2048, 28, 28, 1))\n",
    "test = test.reshape((20480, 28, 28, 1))\n",
    "onehot_letter = onehot_letter.reshape((2048, 1, 26))\n",
    "onehot_test_letter = onehot_test_letter.reshape((20480, 1, 26))\n",
    "\n",
    "xtrain = xtrain.astype('float32')\n",
    "test = test.astype('float32')\n",
    "onehot_letter = onehot_letter.astype('float32')\n",
    "onehot_test_letter = onehot_test_letter.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(2048, 28, 28, 1)\n(20480, 28, 28, 1)\n(2048, 1, 26)\n(20480, 1, 26)\n"
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(test.shape)\n",
    "print(onehot_letter.shape)\n",
    "print(onehot_test_letter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale = 1./255.0,\n",
    "    width_shift_range = 5,\n",
    "    height_shift_range = 5,\n",
    "    rotation_range = 10,\n",
    "    zoom_range = 0.05\n",
    ")\n",
    "datagen.fit(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = Input(shape = (28, 28, 1), dtype = 'float32', name = 'image')\n",
    "letter_input = Input(shape = (1, 26), dtype = 'float32', name = 'letter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nimage (InputLayer)              [(None, 28, 28, 1)]  0                                            \n__________________________________________________________________________________________________\nzero_padding2d_1 (ZeroPadding2D (None, 30, 30, 1)    0           image[0][0]                      \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 30, 30, 128)  1280        zero_padding2d_1[0][0]           \n__________________________________________________________________________________________________\nzero_padding2d_2 (ZeroPadding2D (None, 32, 32, 128)  0           conv2d[0][0]                     \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 32, 32, 128)  147584      zero_padding2d_2[0][0]           \n__________________________________________________________________________________________________\nmax_pooling2d (MaxPooling2D)    (None, 16, 16, 128)  0           conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nzero_padding2d_3 (ZeroPadding2D (None, 18, 18, 128)  0           max_pooling2d[0][0]              \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 18, 18, 256)  295168      zero_padding2d_3[0][0]           \n__________________________________________________________________________________________________\nzero_padding2d_4 (ZeroPadding2D (None, 20, 20, 256)  0           conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 20, 20, 256)  590080      zero_padding2d_4[0][0]           \n__________________________________________________________________________________________________\nletter (InputLayer)             [(None, 1, 26)]      0                                            \n__________________________________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)  (None, 10, 10, 256)  0           conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nlstm (LSTM)                     (None, 1, 128)       79360       letter[0][0]                     \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 10, 10, 256)  0           max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nlstm_1 (LSTM)                   (None, 1, 256)       394240      lstm[0][0]                       \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 25600)        0           dropout[0][0]                    \n__________________________________________________________________________________________________\nlstm_2 (LSTM)                   (None, 256)          525312      lstm_1[0][0]                     \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 25856)        0           flatten[0][0]                    \n                                                                 lstm_2[0][0]                     \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 256)          6619392     concatenate[0][0]                \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 256)          0           dense[0][0]                      \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 10)           2570        dropout_1[0][0]                  \n==================================================================================================\nTotal params: 8,654,986\nTrainable params: 8,654,986\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "\n",
    "# cnn = layers.BatchNormalization()(image_input)\n",
    "cnn = layers.ZeroPadding2D((1, 1))(image_input)\n",
    "cnn = layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same')(cnn)\n",
    "cnn = layers.ZeroPadding2D((1, 1))(cnn)\n",
    "# cnn = layers.BatchNormalization()(cnn)\n",
    "cnn = layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same')(cnn)\n",
    "cnn = layers.MaxPooling2D(2, 2)(cnn)\n",
    "# cnn = layers.BatchNormalization()(cnn)\n",
    "cnn = layers.ZeroPadding2D((1, 1))(cnn)\n",
    "cnn = layers.Conv2D(256, (3, 3), activation = 'relu', padding = 'same')(cnn)\n",
    "cnn = layers.ZeroPadding2D((1, 1))(cnn)\n",
    "# cnn = layers.BatchNormalization()(cnn)\n",
    "cnn = layers.Conv2D(256, (3, 3), activation = 'relu', padding = 'same')(cnn)\n",
    "cnn = layers.MaxPooling2D(2, 2)(cnn)\n",
    "cnn = layers.Dropout(0.2)(cnn)\n",
    "cnn = layers.Flatten()(cnn)\n",
    "\n",
    "\n",
    "dnn = layers.LSTM(128, activation = 'relu', return_sequences = True)(letter_input)\n",
    "dnn = layers.LSTM(256, activation = 'relu', return_sequences = True)(dnn)\n",
    "dnn = layers.LSTM(256, activation = 'relu')(dnn)\n",
    "\n",
    "concatenated = layers.concatenate([cnn, dnn])\n",
    "\n",
    "#result = layers.BatchNormalization()(concatenated)\n",
    "result = layers.Dense(256, activation = 'relu')(concatenated)\n",
    "result = layers.Dropout(0.5)(result)\n",
    "result = layers.Dense(10, activation = 'softmax')(result)\n",
    "\n",
    "model = Model([image_input, letter_input], result)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZER = tf.keras.optimizers.Adamax(0.1)\n",
    "# OPTIMIZER = tf.keras.optimizers.RMSprop(0.01)\n",
    "# OPTIMIZER = tf.keras.optimizers.SGD(0.1)\n",
    "# OPTIMIZER = tf.keras.optimizers.Adagrad(0.01)\n",
    "# OPTIMIZER = tf.keras.optimizers.Adam(0.001)\n",
    "# OPTIMIZER = RAdam(learning_rate = 0.001, warmup_proportion = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "EarlyStopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', patience = 10)\n",
    "ModelCheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath = 'best_model.h5', monitor = 'val_loss', save_weights_only = True, save_best_only = True)\n",
    "ReduceLROnPlateau = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', patience = 5, factor = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(RAdam(),\n",
    "                loss = 'categorical_crossentropy',\n",
    "                metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "`x` (images tensor) and `y` (labels) should have the same length. Found: x.shape = (), y.shape = (2048, 10)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-54f7bbc2f619>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model.fit_generator(\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'image'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'letter'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0monehot_letter\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monehot_ytrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py\u001b[0m in \u001b[0;36mflow\u001b[1;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, subset)\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m             \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m         )\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\numpy_array_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[0;32m     87\u001b[0m                              \u001b[1;34m'should have the same length. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                              \u001b[1;34m'Found: x.shape = %s, y.shape = %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                              (np.asarray(x).shape, np.asarray(y).shape))\n\u001b[0m\u001b[0;32m     90\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             raise ValueError('`x` (images tensor) and `sample_weight` '\n",
      "\u001b[1;31mValueError\u001b[0m: `x` (images tensor) and `y` (labels) should have the same length. Found: x.shape = (), y.shape = (2048, 10)"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    datagen.flow({'image' : xtrain, 'letter' : onehot_letter}, onehot_ytrain, batch_size = 32),\n",
    "    epochs = 150,\n",
    "    steps_per_epoch = 100,\n",
    "    verbose = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/150\n116/116 [==============================] - 39s 335ms/step - loss: 2.2533 - accuracy: 0.1454 - val_loss: 2.0646 - val_accuracy: 0.1463 - lr: 0.0010\nEpoch 2/150\n116/116 [==============================] - 35s 299ms/step - loss: 1.7608 - accuracy: 0.3842 - val_loss: 1.2508 - val_accuracy: 0.6244 - lr: 0.0010\nEpoch 3/150\n116/116 [==============================] - 34s 291ms/step - loss: 1.1619 - accuracy: 0.6169 - val_loss: 0.7755 - val_accuracy: 0.7268 - lr: 0.0010\nEpoch 4/150\n116/116 [==============================] - 34s 290ms/step - loss: 0.8477 - accuracy: 0.7179 - val_loss: 0.6669 - val_accuracy: 0.7561 - lr: 0.0010\nEpoch 5/150\n116/116 [==============================] - 30s 262ms/step - loss: 0.6509 - accuracy: 0.7835 - val_loss: 0.5409 - val_accuracy: 0.8244 - lr: 0.0010\nEpoch 6/150\n116/116 [==============================] - 31s 265ms/step - loss: 0.5271 - accuracy: 0.8275 - val_loss: 0.5056 - val_accuracy: 0.8439 - lr: 0.0010\nEpoch 7/150\n116/116 [==============================] - 31s 264ms/step - loss: 0.4196 - accuracy: 0.8687 - val_loss: 0.4140 - val_accuracy: 0.8732 - lr: 0.0010\nEpoch 8/150\n116/116 [==============================] - 31s 266ms/step - loss: 0.3541 - accuracy: 0.8779 - val_loss: 0.4799 - val_accuracy: 0.8732 - lr: 0.0010\nEpoch 9/150\n116/116 [==============================] - 31s 269ms/step - loss: 0.2879 - accuracy: 0.8991 - val_loss: 0.4358 - val_accuracy: 0.8537 - lr: 0.0010\nEpoch 10/150\n116/116 [==============================] - 30s 260ms/step - loss: 0.2311 - accuracy: 0.9235 - val_loss: 0.5828 - val_accuracy: 0.8439 - lr: 0.0010\nEpoch 11/150\n116/116 [==============================] - 30s 260ms/step - loss: 0.1853 - accuracy: 0.9349 - val_loss: 0.4726 - val_accuracy: 0.8829 - lr: 0.0010\nEpoch 12/150\n116/116 [==============================] - 30s 261ms/step - loss: 0.1634 - accuracy: 0.9457 - val_loss: 0.5524 - val_accuracy: 0.8585 - lr: 0.0010\nEpoch 13/150\n116/116 [==============================] - 30s 262ms/step - loss: 0.0827 - accuracy: 0.9685 - val_loss: 0.4691 - val_accuracy: 0.8683 - lr: 1.0000e-04\nEpoch 14/150\n116/116 [==============================] - 30s 260ms/step - loss: 0.0567 - accuracy: 0.9821 - val_loss: 0.4510 - val_accuracy: 0.8683 - lr: 1.0000e-04\nEpoch 15/150\n116/116 [==============================] - 30s 260ms/step - loss: 0.0403 - accuracy: 0.9886 - val_loss: 0.4729 - val_accuracy: 0.8780 - lr: 1.0000e-04\nEpoch 16/150\n116/116 [==============================] - 30s 263ms/step - loss: 0.0432 - accuracy: 0.9837 - val_loss: 0.4877 - val_accuracy: 0.8829 - lr: 1.0000e-04\nEpoch 17/150\n116/116 [==============================] - 30s 260ms/step - loss: 0.0281 - accuracy: 0.9924 - val_loss: 0.4845 - val_accuracy: 0.8780 - lr: 1.0000e-04\nEpoch 18/150\n116/116 [==============================] - 30s 260ms/step - loss: 0.0258 - accuracy: 0.9924 - val_loss: 0.4920 - val_accuracy: 0.8780 - lr: 1.0000e-05\nEpoch 19/150\n116/116 [==============================] - 30s 260ms/step - loss: 0.0266 - accuracy: 0.9929 - val_loss: 0.4955 - val_accuracy: 0.8780 - lr: 1.0000e-05\nEpoch 20/150\n116/116 [==============================] - 30s 260ms/step - loss: 0.0265 - accuracy: 0.9924 - val_loss: 0.4930 - val_accuracy: 0.8780 - lr: 1.0000e-05\nEpoch 21/150\n116/116 [==============================] - 30s 260ms/step - loss: 0.0363 - accuracy: 0.9832 - val_loss: 0.4924 - val_accuracy: 0.8878 - lr: 1.0000e-05\nEpoch 22/150\n116/116 [==============================] - 30s 262ms/step - loss: 0.0332 - accuracy: 0.9902 - val_loss: 0.4939 - val_accuracy: 0.8829 - lr: 1.0000e-05\nEpoch 23/150\n116/116 [==============================] - 30s 260ms/step - loss: 0.0266 - accuracy: 0.9919 - val_loss: 0.4941 - val_accuracy: 0.8829 - lr: 1.0000e-06\nEpoch 24/150\n116/116 [==============================] - 30s 261ms/step - loss: 0.0258 - accuracy: 0.9913 - val_loss: 0.4923 - val_accuracy: 0.8829 - lr: 1.0000e-06\nEpoch 25/150\n116/116 [==============================] - 30s 260ms/step - loss: 0.0324 - accuracy: 0.9881 - val_loss: 0.4923 - val_accuracy: 0.8829 - lr: 1.0000e-06\nEpoch 26/150\n116/116 [==============================] - 30s 261ms/step - loss: 0.0278 - accuracy: 0.9902 - val_loss: 0.4912 - val_accuracy: 0.8829 - lr: 1.0000e-06\nEpoch 27/150\n116/116 [==============================] - 30s 263ms/step - loss: 0.0251 - accuracy: 0.9946 - val_loss: 0.4911 - val_accuracy: 0.8829 - lr: 1.0000e-06\nEpoch 28/150\n116/116 [==============================] - 30s 261ms/step - loss: 0.0265 - accuracy: 0.9935 - val_loss: 0.4912 - val_accuracy: 0.8829 - lr: 1.0000e-07\nEpoch 29/150\n116/116 [==============================] - 31s 271ms/step - loss: 0.0308 - accuracy: 0.9902 - val_loss: 0.4911 - val_accuracy: 0.8829 - lr: 1.0000e-07\nEpoch 30/150\n116/116 [==============================] - 31s 264ms/step - loss: 0.0220 - accuracy: 0.9940 - val_loss: 0.4910 - val_accuracy: 0.8829 - lr: 1.0000e-07\nEpoch 31/150\n116/116 [==============================] - 30s 261ms/step - loss: 0.0294 - accuracy: 0.9891 - val_loss: 0.4911 - val_accuracy: 0.8829 - lr: 1.0000e-07\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x205884d5a08>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "model.fit(\n",
    "    {'image' : xtrain, 'letter' : onehot_letter}, onehot_ytrain,\n",
    "    batch_size = 16,\n",
    "    epochs = 150,\n",
    "    verbose = 1,\n",
    "    validation_split = 0.10,\n",
    "    callbacks = [EarlyStopping, ModelCheckpoint, ReduceLROnPlateau]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Tensorboard Link](http://localhost:6006)  \n",
    "71/71 [==============================] - 13s 181ms/step - loss: 0.0737 - accuracy: 0.9756 - val_loss: 0.5013 - val_accuracy: 0.8244  85%\n",
    "\n",
    "Epoch 11/150\n",
    "58/58 [==============================] - 18s 316ms/step - loss: 0.2306 - accuracy: 0.9143 - val_loss: 0.4259 - val_accuracy: 0.8585 - lr: 0.0010 87%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       digit\n0          6\n1          9\n2          8\n3          0\n4          3\n...      ...\n20475      4\n20476      1\n20477      6\n20478      8\n20479      0\n\n[20480 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>digit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20475</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>20476</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20477</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>20478</th>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>20479</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>20480 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "y_pred = model.predict({'image' : test, 'letter' : onehot_test_letter}, batch_size=32)\n",
    "# digit  디코딩\n",
    "decoding = np.argmax(y_pred, axis=1).reshape(-1,1)\n",
    "decoding = pd.DataFrame(decoding, columns = ['digit'])\n",
    "decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "sorted(decoding['digit'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       digit\n0          6\n1          9\n2          8\n3          0\n4          3\n...      ...\n20475      4\n20476      1\n20477      6\n20478      1\n20479      0\n\n[20480 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>digit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20475</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>20476</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20477</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>20478</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20479</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>20480 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "model.load_weights('best_model.h5')\n",
    "y_pred = model.predict({'image' : test, 'letter' : onehot_test_letter}, batch_size=32)\n",
    "# digit  디코딩\n",
    "decoding = np.argmax(y_pred, axis=1).reshape(-1,1)\n",
    "decoding = pd.DataFrame(decoding, columns = ['digit'])\n",
    "decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          id  digit\n0       2049      6\n1       2050      9\n2       2051      8\n3       2052      0\n4       2053      3\n...      ...    ...\n20475  22524      4\n20476  22525      1\n20477  22526      6\n20478  22527      1\n20479  22528      0\n\n[20480 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>digit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2049</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2050</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2051</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2052</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2053</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20475</th>\n      <td>22524</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>20476</th>\n      <td>22525</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20477</th>\n      <td>22526</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>20478</th>\n      <td>22527</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20479</th>\n      <td>22528</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>20480 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "sub = pd.read_csv('data/submission.csv')\n",
    "sub = sub.drop(['digit'], axis = 1)\n",
    "sub = pd.concat([sub, decoding], axis = 1)\n",
    "sub.to_csv('sub.csv', index = False, encoding = 'utf-8')\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ]
}